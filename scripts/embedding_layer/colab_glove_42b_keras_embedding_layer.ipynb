{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-Jitrv8mIngM",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "QnalTZlN0k0c",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#note: this causes the environment to crash and restart with such a huge file. for now, we are just using wget instead of Google Drive.\n",
    "#wget is surprisingly fast for this task, possibly moreso than Google Drive would be.\n",
    "\n",
    "#from documentation at https://colab.research.google.com/notebook#fileId=/v2/external/notebooks/io.ipynb&scrollTo=vz-jH8T_Uk2c:\n",
    "#authenticate to access Google Drive using the REST API\n",
    "#from google.colab import auth\n",
    "#auth.authenticate_user()\n",
    "\n",
    "#create a drive client:\n",
    "#from googleapiclient.discovery import build\n",
    "#drive_service = build('drive', 'v3')\n",
    "\n",
    "#getting the glove file\n",
    "\n",
    "#import io\n",
    "#from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "#file_id = '18DZMqkgq5_nXgDEk9zc1HT7twmLuMEBk'\n",
    "#request = drive_service.files().get_media(fileId = file_id)\n",
    "#glove_downloaded = io.BytesIO()\n",
    "#downloader = MediaIoBaseDownload(glove_downloaded, request)\n",
    "\n",
    "#done = False\n",
    "#while done is False:\n",
    "#  _, done = downloader.next_chunk()\n",
    "#glove_downloaded.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iNNgBGagDV5L",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#download the glove word embedding from Stanford NLP:\n",
    "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iKvrF3OKDk11",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "outputId": "50f935d9-6d11-4954-a580-24e08a87d072",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.524295053853E12,
     "user_tz": 240.0,
     "elapsed": 53545.0,
     "user": {
      "displayName": "Nanak Nihal Khalsa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100787844473172298543"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.42B.300d.zip\n",
      "  inflating: glove.42B.300d.txt      \n"
     ]
    }
   ],
   "source": [
    "!unzip glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vb9h6EuR3xJ6",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#files = files.upload()\n",
    "#Inspired by https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py\n",
    "#and the Emojify exercise from Andrew Ng's course on sequence models\n",
    "word_to_index = {}\n",
    "word_to_vector = {} #not to be confused with word2vec\n",
    "\n",
    "#open the file:\n",
    "with open('glove.42B.300d.txt') as f:\n",
    "  i = 0\n",
    "  for line in f:\n",
    "    split_line = line.split()\n",
    "    word = split_line[0]\n",
    "    weights = np.asarray(split_line[1:])\n",
    "    #store the weight vector at the appropriate index:\n",
    "    word_to_vector[word] = weights\n",
    "    word_to_index[word] = i\n",
    "    i += 1 #no ++ in python\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "s6y82v_vICom",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "TSrqt-fF7UwA",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#generates a Keras embedding layer, inspired by Emojify in Andrew Ng's Sequence Models Coursera course\n",
    "def gen_embedding_layer():\n",
    "  input_size = len(word_to_index) + 1 #Keras requires this to be the vocab size + 1\n",
    "  output_size = word_to_vector[\"bamboozled\"].shape[0]\n",
    "  \n",
    "  embedding_matrix = np.zeros((input_size, output_size))\n",
    "  for word, index in word_to_index.items():\n",
    "    embedding_matrix[index, :] = word_to_vector[word] \n",
    " \n",
    "\n",
    "  layer = keras.layers.Embedding(input_size, output_size, trainable=False)\n",
    "  layer.build((None,))\n",
    "  layer.set_weights([embedding_matrix])\n",
    "  return layer\n",
    "  \n",
    "gen_embedding_layer()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": [
    {
     "file_id": "1YVuQRV09QYao0-f5Oxu6x-3O9QdmVony",
     "timestamp": 1.524447433189E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python2",
   "display_name": "Python 2"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
